{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Maternal Health Risk Study A**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Answer Buisiness requirement 1. Carry out descriptive analytics on the maternal health dataset.\n",
        "  \n",
        "## Inputs\n",
        "\n",
        "* The maternal health dataset from outputs/datasets/collection/maternal-healt-dataset.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Code to answer business requirement 1 and to use to build a Streamlit dashboard\n",
        "* Plots to visualise the analysis\n",
        "\n",
        "## Additional Comments\n",
        "* This is the first part of the maternal health risk study and contains exploratory data analysis of the data set, outlier study and correlation study.\n",
        "* See part B of this notebook for the rest of the analysis (EDA of selected correlated variables)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import Packages for Data Collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from ydata_profiling import ProfileReport\n",
        "import plotly.express as px\n",
        "from feature_engine.discretisation import ArbitraryDiscretiser\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* Access current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Make the parent of the current directory the new current directory, and confirm new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory\n",
        "* os.getcwd() get the current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "current_dir = os.getcwd()\n",
        "print(f\"New current directory set to {current_dir}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('outputs/datasets/collection/maternal-health-risk-dataset.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this section we perform a first exploratory data analysis on the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pandas_report = ProfileReport(df=df, minimal=True)\n",
        "pandas_report.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Notes from the profiling report:\n",
        "\n",
        "* The target variable (RiskLevel) has three classes and 40% of the target variables are zero (low risk).\n",
        "  * This could be a hint that the dataset is imbalanced.\n",
        "  * Depending on the balance of the other two classes, this could indicate significant or mild imbalance and we might need to consider rebalancing the dataset during the feature engineering step.\n",
        "  * The class distribution is: 40%, 33.1%, 26.8%. This is a more moderate imbalance and ML algorithms might perform well enough without rebalancing.\n",
        "  * We will keep this in mind for the case where one class has notably worse results in prediction.\n",
        "* There are no missing values in any column."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Outlier Study\n",
        "\n",
        "In this section we look at outliers to get a first impression and see whether there could be possible errors in the dataset.\n",
        "\n",
        "We will further handle the outliers in the data cleaning and feature engineering notebooks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Short Statictical Summary\n",
        "\n",
        "We look at a quick statistical summary of the dataset to check the averages and also the min and max to get a first impression on possible outliers/extreme values etc. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We notice that the minimum value for age is 10 and the maximum value for age ist 70 years old, which seems odd for data about pregnancy.\n",
        "  * We will decide in the data cleaning notebook how to proceed with the extreme values for age.\n",
        "* Since we look at medical data, it is useful to gather information about normal ranges of the other variables:\n",
        "  * Blood Pressure (mm Hg) (from [Blood Pressure UK](https://www.bloodpressureuk.org/your-blood-pressure/understanding-your-blood-pressure/what-do-the-numbers-mean/)):\n",
        "    * low blood pressure: 70-90 systolic and 40-60 diastolic\n",
        "    * ideal blood pressure: 90-120 systolic and 60-80 diastolic\n",
        "    * pre-high blood pressure: 120-140 systolic and 80-90 diastolic\n",
        "    * high blood pressure: 140-190 systolic and 90-100 diastolic\n",
        "    * Blood pressure values in the dataset look to be in a realistic range\n",
        "  * Blood Sugar (mmol/L):\n",
        "    * We do not have enough details about the measurement (i.e. at what time was the measurement taken etc.) to know whether min and max values are in a realistic range, we have to assume they are and consider the outlier analysis as usual.\n",
        "  * Body Temperature looks to be in a normal range.\n",
        "  * Heart Rate seems to be in a normal range."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To visualise the outliers, let us create a boxplot for each variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for var in df.columns[:-1]:\n",
        "    plt.figure(figsize=(4,4))\n",
        "    sns.boxplot(data=df[var])\n",
        "    plt.title(f\"{var} Box Plot\", fontsize=15, y=1.05)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Correlation Study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this section we study correlation in the dataset.\n",
        "\n",
        "We are interested in\n",
        "* the correlation of each feature with the target\n",
        "* correlation between the features to find possible collinearity\n",
        "\n",
        "Note that the focus in this notebook is on the correlation of the features with the target variable. We leave a more detailed study of the correlations between the features to the feature engineering notebook, where it comes to deciding which features to train the ML model on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We start by looking at the correlation levels of RiskLevel with all the features. We drop the correlation of the target with itself and sort the correlation levels by absolute value (key=abs) in descending order to find the most relevant correlated variables.\n",
        "\n",
        "Since the variables are not normally distributed and not all of them (most notably the target) are continuous, the Spearman's correlation is the one we have to consider. \n",
        "\n",
        "With our discrete target variable Pearson's correlation does not make sense."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_vars_spearman = df.corr(method='spearman')[\"RiskLevel\"].sort_values(key=abs, ascending=False).drop(\"RiskLevel\")\n",
        "corr_vars_spearman"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Heatmap\n",
        "\n",
        "Let us now visualise the correlations of all variables in a heatmap.\n",
        "\n",
        "We will look into this in more detail in the feature engineering notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_corr = df.corr(method=\"spearman\")\n",
        "# Create a mask to cover the upper triangle of the heatmap since the data is symetric\n",
        "# Get zeros in the shape of df_corr of boolean type\n",
        "upper_mask = np.zeros_like(df_corr, dtype=np.bool)\n",
        "# Select all indices in the upper right triangle and set to True\n",
        "upper_mask[np.triu_indices_from(upper_mask)] = True\n",
        "sns.heatmap(data=df_corr, annot=True, mask=upper_mask, linewidths=0.7, annot_kws={\"size\": 9}, cmap='crest')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Conclusions from Correlation Study\n",
        "\n",
        "* For both methods we notice mostly weak and some moderate correlation levels between the target and the features.\n",
        "* The variable with the strongest correlation is BloodSugar.\n",
        "* We include all variables with correlation levels greate than 0.2 in the further study.\n",
        "* Hence, we drop HeartRate and BodyTemp for now since they only correlate weakly to the RiskLevel.\n",
        "* Also note that all correlation levels are positive meaning that when one variable increases also the RiskLevel increases.\n",
        "* Most notable this analysis leads us to suspect that:\n",
        "  * Patients with high risk tend to have high blood sugar levels\n",
        "  * Patients with high risk tend to have high systolic blood pressure levels\n",
        "  * Patients with high risk tend to have high diasystolic blood pressure levels\n",
        "  * Patients with high risk tend to are of a higher age\n",
        "\n",
        "We now take the four weak to moderately correlated variables, store them in corr_vars and perform further analysis in the next section. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_vars_study = corr_vars_spearman[:4].index.to_list()\n",
        "corr_vars_study "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusions and Next Steps\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We continue our analysis in the next notebook 03-MaternalHealthRiskStudyB.ipynb"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
